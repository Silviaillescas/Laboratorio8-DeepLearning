{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "791ef42f",
   "metadata": {},
   "source": [
    "\n",
    "# CC3045 – Deep Learning y Sistemas Inteligentes  \n",
    "## Laboratorio 8 — **Task 1 (Kaggle-ready)**: LSTM para *Store Item Demand Forecasting*\n",
    "\n",
    "Autoras: Michelle Mejia y Silvia Illescas\n",
    "\n",
    "Este notebook incluye preparación de datos, ventanas, LSTM, entrenamiento, evaluación y **creación de `submission.csv` alineado con `test.csv` (id,date,store,item)** para la competencia:\n",
    "**`demand-forecasting-kernels-only`**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cab08a",
   "metadata": {},
   "source": [
    "## 1) Imports y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bcf6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "TensorFlow: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install pandas numpy matplotlib scikit-learn\n",
    "\n",
    "\n",
    "import os, math, json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_PATH  = os.path.join(DATA_DIR, 'test.csv')\n",
    "SAMPLE_SUB_PATH = os.path.join(DATA_DIR, 'sample_submission.csv')\n",
    "\n",
    "assert os.path.exists(TRAIN_PATH), f'No se encontró {TRAIN_PATH}'\n",
    "assert os.path.exists(TEST_PATH),  f'No se encontró {TEST_PATH}'\n",
    "print('TensorFlow:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866d4d2f",
   "metadata": {},
   "source": [
    "## 2) Cargar datos y *overview*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d328293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store  item  sales\n",
       "0 2013-01-01      1     1     13\n",
       "1 2013-01-02      1     1     11\n",
       "2 2013-01-03      1     1     14\n",
       "3 2013-01-04      1     1     13\n",
       "4 2013-01-05      1     1     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store  item\n",
       "0   0 2018-01-01      1     1\n",
       "1   1 2018-01-02      1     1\n",
       "2   2 2018-01-03      1     1\n",
       "3   3 2018-01-04      1     1\n",
       "4   4 2018-01-05      1     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rango de fechas:\n",
      "Train: 2013-01-01 00:00:00 → 2017-12-31 00:00:00\n",
      "Test : 2018-01-01 00:00:00 → 2018-03-31 00:00:00\n",
      "\n",
      "Series únicas (store,item): 500\n",
      "Series en test (store,item): 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# conversion de fechas\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date']  = pd.to_datetime(test['date'])\n",
    "\n",
    "train = train.sort_values(['store','item','date']).reset_index(drop=True)\n",
    "test  = test.sort_values(['store','item','date']).reset_index(drop=True)\n",
    "\n",
    "print('Train head:'); display(train.head())\n",
    "print('Test head:'); display(test.head())\n",
    "\n",
    "print('\\nRango de fechas:')\n",
    "print('Train:', train['date'].min(), '→', train['date'].max())\n",
    "print('Test :', test['date'].min(), '→', test['date'].max())\n",
    "\n",
    "print('\\nSeries únicas (store,item):', train[['store','item']].drop_duplicates().shape[0])\n",
    "print('Series en test (store,item):', test[['store','item']].drop_duplicates().shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405f9ca",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Limpieza y *feature engineering*\n",
    "- Relleno de nulos en `sales` (si hubiera)\n",
    "- Recorte de *outliers* por percentil alto\n",
    "- Rasgos de calendario\n",
    "- Objetivo en `log1p`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67cd16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = train.copy()\n",
    "df['sales'] = df['sales'].fillna(0)\n",
    "cap = df['sales'].quantile(0.999)\n",
    "df['sales'] = np.clip(df['sales'], 0, cap)\n",
    "\n",
    "def add_time_features(d):\n",
    "    d['dow']   = d['date'].dt.dayofweek.astype('int16')\n",
    "    d['week']  = d['date'].dt.isocalendar().week.astype('int16')\n",
    "    d['month'] = d['date'].dt.month.astype('int16')\n",
    "    d['year']  = d['date'].dt.year.astype('int16')\n",
    "    d['day']   = d['date'].dt.day.astype('int16')\n",
    "    return d\n",
    "\n",
    "df  = add_time_features(df)\n",
    "test_feat = add_time_features(test.copy())\n",
    "\n",
    "df['sales_log1p'] = np.log1p(df['sales'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f870f",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Ventanas (WINDOW) y horizonte (HORIZON = 90 días)\n",
    "Se entrena **un único modelo** para todas las series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91b9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (853500, 30, 7) y: (853500, 90)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "WINDOW  = 30\n",
    "HORIZON = 90\n",
    "TARGET  = 'sales_log1p'\n",
    "\n",
    "feature_cols = ['dow','week','month','year','day','store','item']\n",
    "cont_cols    = ['dow','week','month','year','day']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def build_sequences(group_df):\n",
    "    X_seq, y_seq = [], []\n",
    "    g = group_df.sort_values('date').copy()\n",
    "    feat = g[feature_cols].copy()\n",
    "    feat[cont_cols] = scaler.fit_transform(feat[cont_cols])\n",
    "    y = g[TARGET].values\n",
    "\n",
    "    for i in range(len(g) - WINDOW - HORIZON + 1):\n",
    "        X_seq.append(feat.iloc[i:i+WINDOW].values)\n",
    "        y_seq.append(y[i+WINDOW:i+WINDOW+HORIZON])\n",
    "    return np.array(X_seq, dtype=np.float32), np.array(y_seq, dtype=np.float32)\n",
    "\n",
    "X_list, y_list = [], []\n",
    "for (s,it), g in df.groupby(['store','item'], sort=False):\n",
    "    Xg, yg = build_sequences(g)\n",
    "    if len(Xg):\n",
    "        X_list.append(Xg); y_list.append(yg)\n",
    "\n",
    "X = np.vstack(X_list)\n",
    "y = np.vstack(y_list)\n",
    "\n",
    "print('X:', X.shape, 'y:', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a9b686",
   "metadata": {},
   "source": [
    "## 5) Split temporal: train/val/test (por índice de ventanas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb408199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((597450, 30, 7),\n",
       " (597450, 90),\n",
       " (128025, 30, 7),\n",
       " (128025, 90),\n",
       " (128025, 30, 7),\n",
       " (128025, 90))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n = len(X)\n",
    "test_frac = 0.15\n",
    "val_frac  = 0.15\n",
    "n_test = int(n * test_frac)\n",
    "n_val  = int(n * val_frac)\n",
    "n_train = n - n_val - n_test\n",
    "\n",
    "X_train, y_train = X[:n_train], y[:n_train]\n",
    "X_val,   y_val   = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "X_test,  y_test  = X[n_train+n_val:], y[n_train+n_val:]\n",
    "tuple(arr.shape for arr in [X_train, y_train, X_val, y_val, X_test, y_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191e1521",
   "metadata": {},
   "source": [
    "## 6) Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941bf6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,610</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m18,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m)             │        \u001b[38;5;34m11,610\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,874</span> (151.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,874\u001b[0m (151.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,618</span> (150.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,618\u001b[0m (150.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_features = X.shape[2]\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(WINDOW, n_features)),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(HORIZON)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse', metrics=[keras.metrics.MeanAbsoluteError(name='mae')])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68305c4a",
   "metadata": {},
   "source": [
    "## 7) Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e2851cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 43ms/step - loss: 2.6929 - mae: 1.0639 - val_loss: 0.5889 - val_mae: 0.6850 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 45ms/step - loss: 0.2141 - mae: 0.3707 - val_loss: 0.4957 - val_mae: 0.6216 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 43ms/step - loss: 0.1843 - mae: 0.3406 - val_loss: 0.4438 - val_mae: 0.5999 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 45ms/step - loss: 0.1546 - mae: 0.3072 - val_loss: 0.4459 - val_mae: 0.6103 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 44ms/step - loss: 0.1051 - mae: 0.2520 - val_loss: 0.3792 - val_mae: 0.5779 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 44ms/step - loss: 0.0742 - mae: 0.2141 - val_loss: 0.3370 - val_mae: 0.5465 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 45ms/step - loss: 0.0638 - mae: 0.1985 - val_loss: 0.4189 - val_mae: 0.6190 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 44ms/step - loss: 0.0613 - mae: 0.1934 - val_loss: 0.3561 - val_mae: 0.5687 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 42ms/step - loss: 0.0593 - mae: 0.1895 - val_loss: 0.3760 - val_mae: 0.5840 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 42ms/step - loss: 0.0545 - mae: 0.1819 - val_loss: 0.3323 - val_mae: 0.5477 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 44ms/step - loss: 0.0531 - mae: 0.1794 - val_loss: 0.3336 - val_mae: 0.5477 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 44ms/step - loss: 0.0514 - mae: 0.1764 - val_loss: 0.3100 - val_mae: 0.5274 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 56ms/step - loss: 0.0498 - mae: 0.1735 - val_loss: 0.3113 - val_mae: 0.5290 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 60ms/step - loss: 0.0472 - mae: 0.1693 - val_loss: 0.3096 - val_mae: 0.5312 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 58ms/step - loss: 0.0442 - mae: 0.1643 - val_loss: 0.3150 - val_mae: 0.5360 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 55ms/step - loss: 0.0433 - mae: 0.1624 - val_loss: 0.3110 - val_mae: 0.5322 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 54ms/step - loss: 0.0423 - mae: 0.1606 - val_loss: 0.3077 - val_mae: 0.5293 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 54ms/step - loss: 0.0418 - mae: 0.1594 - val_loss: 0.3180 - val_mae: 0.5388 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 177ms/step - loss: 0.0408 - mae: 0.1576 - val_loss: 0.3137 - val_mae: 0.5337 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 59ms/step - loss: 0.0406 - mae: 0.1570 - val_loss: 0.2999 - val_mae: 0.5216 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 54ms/step - loss: 0.0401 - mae: 0.1560 - val_loss: 0.3058 - val_mae: 0.5263 - learning_rate: 5.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 58ms/step - loss: 0.0400 - mae: 0.1556 - val_loss: 0.3205 - val_mae: 0.5393 - learning_rate: 5.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 58ms/step - loss: 0.0400 - mae: 0.1556 - val_loss: 0.3109 - val_mae: 0.5312 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 55ms/step - loss: 0.0390 - mae: 0.1536 - val_loss: 0.3038 - val_mae: 0.5259 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 54ms/step - loss: 0.0388 - mae: 0.1532 - val_loss: 0.2996 - val_mae: 0.5218 - learning_rate: 2.5000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 56ms/step - loss: 0.0386 - mae: 0.1528 - val_loss: 0.3143 - val_mae: 0.5358 - learning_rate: 2.5000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 59ms/step - loss: 0.0385 - mae: 0.1524 - val_loss: 0.3051 - val_mae: 0.5268 - learning_rate: 2.5000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 55ms/step - loss: 0.0383 - mae: 0.1521 - val_loss: 0.3103 - val_mae: 0.5320 - learning_rate: 2.5000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 55ms/step - loss: 0.0380 - mae: 0.1514 - val_loss: 0.3063 - val_mae: 0.5285 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m2334/2334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 55ms/step - loss: 0.0379 - mae: 0.1512 - val_loss: 0.3024 - val_mae: 0.5249 - learning_rate: 1.2500e-04\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.038563</td>\n",
       "      <td>0.152657</td>\n",
       "      <td>0.314335</td>\n",
       "      <td>0.535817</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.038441</td>\n",
       "      <td>0.152340</td>\n",
       "      <td>0.305056</td>\n",
       "      <td>0.526793</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.038274</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.310331</td>\n",
       "      <td>0.532047</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.037956</td>\n",
       "      <td>0.151286</td>\n",
       "      <td>0.306252</td>\n",
       "      <td>0.528453</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.037892</td>\n",
       "      <td>0.151143</td>\n",
       "      <td>0.302355</td>\n",
       "      <td>0.524884</td>\n",
       "      <td>0.000125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       mae  val_loss   val_mae  learning_rate\n",
       "25  0.038563  0.152657  0.314335  0.535817       0.000250\n",
       "26  0.038441  0.152340  0.305056  0.526793       0.000250\n",
       "27  0.038274  0.152000  0.310331  0.532047       0.000250\n",
       "28  0.037956  0.151286  0.306252  0.528453       0.000125\n",
       "29  0.037892  0.151143  0.302355  0.524884       0.000125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-5)\n",
    "]\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "pd.DataFrame(history.history).tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667bc0c",
   "metadata": {},
   "source": [
    "## 8) Evaluación interna (RMSE/MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c753d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  24.629\n",
      "RMSE: 29.252\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def inv_log1p(x): return np.expm1(x)\n",
    "\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "mae = mean_absolute_error(inv_log1p(y_test).ravel(), inv_log1p(y_pred).ravel())\n",
    "mse = mean_squared_error(inv_log1p(y_test).ravel(), inv_log1p(y_pred).ravel())\n",
    "rmse = math.sqrt(mse)\n",
    "print(f\"MAE:  {mae:,.3f}\\nRMSE: {rmse:,.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e85566d",
   "metadata": {},
   "source": [
    "\n",
    "## 9) **Forecast para `test.csv` y creación de `submission.csv`**\n",
    "- Para cada `(store,item)` en `test`, se toma la **última ventana** de 30 días inmediatamente anterior al primer día de `test` (esto coincide con que `train` llega hasta 2017-12-31 y `test` arranca 2018-01-01).\n",
    "- Se generan **90 días** de pronóstico (HORIZON) y luego se **empareja por (date,store,item)** con el `test`.\n",
    "- Finalmente, se respeta el **orden original de `test.id`**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510818b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Preparar última ventana por (store,item) usando train\n",
    "def last_window_for_group(g):\n",
    "    g = g.sort_values('date').copy()\n",
    "    feat = g[feature_cols].copy()\n",
    "    feat[cont_cols] = scaler.fit_transform(feat[cont_cols])\n",
    "    if len(feat) < WINDOW:\n",
    "        return None\n",
    "    return feat.iloc[-WINDOW:].values.astype(np.float32)\n",
    "\n",
    "# Fecha de inicio de test (por serie); el test puede tener 90 días seguidos por serie\n",
    "first_test_date = test['date'].min()\n",
    "\n",
    "# 2) Generar pronóstico horizonte=90 para cada (store,item) que aparece en test\n",
    "pred_rows = []\n",
    "for (s,it), gtest in test.groupby(['store','item'], sort=False):\n",
    "    gtrain = df[(df['store']==s) & (df['item']==it)]\n",
    "    X_last = last_window_for_group(gtrain)\n",
    "    if X_last is None:\n",
    "        # Si faltan datos, saltar o predecir con constante (fallback)\n",
    "        continue\n",
    "    pred_log = model.predict(X_last[None, :, :], verbose=0)[0]\n",
    "    pred = np.expm1(pred_log)\n",
    "    start_date = gtrain['date'].max() + pd.Timedelta(days=1)\n",
    "    dates = pd.date_range(start=start_date, periods=HORIZON, freq='D')\n",
    "    tmp = pd.DataFrame({'date': dates, 'store': s, 'item': it, 'sales': pred})\n",
    "    pred_rows.append(tmp)\n",
    "\n",
    "forecast_all = pd.concat(pred_rows, ignore_index=True)\n",
    "# 3) Empatar con test exacto por (date, store, item)\n",
    "merged = test.merge(forecast_all, on=['date','store','item'], how='left')\n",
    "\n",
    "# 4) Post-proceso: ventas no negativas y redondeo opcional (normalmente no se requiere)\n",
    "merged['sales'] = merged['sales'].clip(lower=0)\n",
    "\n",
    "# 5) Ordenar por id y exportar\n",
    "submission = merged[['id','sales']].sort_values('id').reset_index(drop=True)\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "sub_path = './outputs/submission.csv'\n",
    "submission.to_csv(sub_path, index=False)\n",
    "print('Guardado:', sub_path)\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523fe21",
   "metadata": {},
   "source": [
    "\n",
    "## 10) Visualización rápida para una serie (opcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example = test[['store','item']].drop_duplicates().iloc[0].tolist()\n",
    "ex_store, ex_item = example\n",
    "gtrain = train[(train['store']==ex_store) & (train['item']==ex_item)].sort_values('date')\n",
    "gtest  = test[(test['store']==ex_store) & (test['item']==ex_item)].sort_values('date')\n",
    "gpred  = submission.merge(test, on='id').query('store==@ex_store and item==@ex_item')\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(gtrain['date'].tail(150), gtrain['sales'].tail(150), label='Real (train, últimos 150 días)')\n",
    "plt.plot(gtest['date'], gpred['sales'], label='Pronóstico (test)')\n",
    "plt.title(f'Store {ex_store} - Item {ex_item}')\n",
    "plt.xlabel('Fecha'); plt.ylabel('Ventas')\n",
    "plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719286e9",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Guardar artefactos\n",
    "- `./outputs/submission.csv` con columnas **id,sales** para subir a Kaggle\n",
    "- `./models/lstm_forecast_90d.keras` para reutilizar el modelo\n",
    "- `./models/metadata.json` con parámetros clave\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1285cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "model.save('./models/lstm_forecast_90d.keras')\n",
    "meta = {\n",
    "    'window': int(WINDOW),\n",
    "    'horizon': int(HORIZON),\n",
    "    'feature_cols': feature_cols,\n",
    "    'cont_cols': cont_cols,\n",
    "    'target': TARGET\n",
    "}\n",
    "with open('./models/metadata.json', 'w') as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "print('Modelo y metadatos guardados en ./models')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
